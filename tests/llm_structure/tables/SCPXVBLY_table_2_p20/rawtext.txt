Model update
component
Update equation
Explanation
Model-specific description for
explore–exploit task (described
in detail Section 3)
Expected free energy
precision
p(γ) = Γ (1, β)
E[γ] = γ = 1/β
Iterated to convergence:
π0 ←σ(ln E −γ G)
π ←σ(ln E −F −γ G)
Gerror ←(π −π0) · (−G)
βupdate ←β −β0 + Gerror
β ←β −βupdate/ψ
γ ←1/β
The β term, and its prior value β0, is a hyperparameter
on the expected free energy precision term (γ).
Specifically, β is the ’rate’ parameter of a gamma
distribution (Γ ) with a ‘shape’ parameter value of 1.
The expected value of this distribution, E [γ] = γ , is
equal to the reciprocal of β. Note that we use the
non-italicized γ to refer to the random variable and use
the italicized γ to refer to the scalar value of that
variable. This scalar is what is subsequently updated
based on the equations shown here.
The γ term controls the precision of G, based on the
agent’s confidence in its estimates of expected free
energy. This confidence changes when new observations
are consistent or inconsistent with G. More specifically,
γ modulates the influence of G on policy selection based
upon a G prediction error (Gerror). This is calculated
based on the difference between the initial distribution
over policies (π0) and the posterior distribution after
making a new observation (π). The difference between
these terms reflects the extent to which new
observations (scored by F) make policies more or less
likely. If the vector encoding the posterior over policies
increases in magnitude in comparison to the prior, and
still points in the same direction, the difference vector
between the posterior and the prior will point in the
same direction as the −G vector (i.e., less than a 90◦
angle apart; see Fig. 9). If so, the value of γ will
increase, thereby increasing the impact of G on policy
selection. In contrast, if the difference vector between
the posterior and the prior does not point in the same
direction as the −G vector (i.e., greater than a 90◦angle
apart), γ will decrease and thereby reduce the impact
of G on policy selection (i.e., as the agent’s confidence
in its estimates of expected free energy has decreased).
Note that the βupdate term mediating these updates
technically corresponds to the gradient of free energy
with respect to γ (∇γ F). The subsequent update in the
value of γ is such that G contributes to the posterior
over policies in an optimal manner. β and Gerror are
often discussed in relation to dopamine in the active
inference literature.
Note that β0 is the initial prior (which is not updated),
A higher value for β would
reduce an agent’s confidence in
the best policy based on the
values in G. This might lead
the agent to select a slot
machine more randomly or
based to a greater extent on
its past choices (i.e., if it has a
precise prior over policies in
the vector E).
