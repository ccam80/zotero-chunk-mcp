Under
ergodic
assumptions,
the
long-term
average
of surprise is entropy. This means that minimizing free
energy—through selectively sampling sensory input—places
an upper bound on the entropy or dispersion of sensory
states. This enables biological systems to resist the second law
of thermodynamics—or more exactly the fluctuation theorem
that applies to open systems far from equilibrium [14,15].
However, because negative surprise is also Bayesian model
evidence, systems that minimize free energy also maximize a
lower bound on the evidence for an implicit model of how
their sensory samples were generated. In statistics and machine
learning, this is known as approximate Bayesian inference and
provides a normative theory for the Bayesian brain hypothesis
[16–20]. In short, biological systems act on the world to place
an upper bound on the dispersion of their sensed states,
while using those sensations to infer external states of the
world. This inference makes the free energy bound a better
approximation to the surprise that action is trying to minimize
[21]. The resulting active inference is closely related to formu-
lations in embodied cognition and artificial intelligence; for
example, the use of predictive information [22–24] and earlier
homeokinetic formulations [25].
The ensuing (variational) free energy principle has been
applied widely in neurobiology and has been generalized
to other biological systems at a more theoretical level [11].
The motivation for minimizing free energy has hitherto used
the following sort of argument: systems that do not mini-
mize free energy cannot exist, because the entropy of their
sensory states would not be bounded and would increase
indefinitely—by the fluctuation theorem [15]. Therefore, bio-
logical systems must minimize free energy. This paper
resolves the somewhat tautological aspect of this argument
by turning it around to suggest: any system that exists will
appear to minimize free energy and therefore engage in
active inference. Furthermore, this apparently inferential or
mindful behaviour is (almost) inevitable. This may sound
like a rather definitive assertion but is surprisingly easy to
verify. In what follows, we will consider a heuristic proof
based on random dynamical systems and then see that bio-
logical self-organization emerges naturally, using a synthetic
primordial soup. This proof of principle rests on four attributes
of—or tests for—self-organization that may themselves have
interesting implications.
2. Heuristic proof
We start with the following lemma: any ergodic random dynami-
cal system that possesses a Markov blanket will appear to actively
maintain its structural and dynamical integrity. We will associate
this behaviour with the self-organization of living organisms.
There are two key concepts here—ergodicity and a Markov
blanket. Here, ergodicity means that the time average of any
measurable function of the system converges (almost surely)
over a sufficient amount of time [26,27]. This means that one
can interpret the average amount of time a state is occupied
as the probability of the system being in that state when
observed at random. We will refer to this probability measure
as the ergodic density.
A Markov blanket is a set of states that separates two
other sets in a statistical sense. The term Markov blanket was
introduced in the context of Bayesian networks or graphs
[28] and refers to the children of a set (the set of states that
are influenced), its parents (the set of states that influence it)
and the parents of its children. The notion of influence or
dependency is central to a Markov blanket and its existence
implies that any state is—or is not—coupled to another. For
example, the system could comprise an ensemble of subsys-
tems, each occupying its own position in a Euclidean space.
If the coupling among subsystems is mediated by short-range
forces, then distant subsystems cannot influence each other.
The existence of a Markov blanket implies that its states
(e.g. motion in Euclidean space) do not affect their coupling or
independence. In other words, the interdependencies among
states comprising the Markov blanket change slowly with
respect to the states per se. For example, the surface of a cell
may constitute a Markov blanket separating intracellular and
extracellular states. On the other hand, a candle flame cannot
possess a Markov blanket, because any pattern of molecular
interactions is destroyed almost instantaneously by the flux
of gas molecules from its surface.
The existence of a Markov blanket induces a partition of
states into internal states and external states that are hidden
(insulated) from the internal (insular) states by the Markov
blanket. In other words, the external states can only be seen
vicariously by the internal states, through the Markov blanket.
Furthermore, the Markov blanket can itself be partitioned into
two sets that are, and are not, children of external states. We
will refer to these as a surface or sensory states and active
states, respectively. Put simply, the existence of a Markov blan-
ket S  A implies a partition of states into external, sensory,
active and internal states: x [ X ¼ C  S  A  L. Exter-
nal states cause sensory states that influence—but are not
influenced by—internal states, while internal states cause
active states that influence—but are not influenced by—
external states (table 1). Crucially, the dependencies induced
by Markov blankets create a circular causality that is reminis-
cent of the action–perception cycle (figure 1). The circular
causality here means that external states cause changes in
internal states, via sensory states, while the internal states
couple back to the external states through active states—such
that internal and external states cause each other in a reciprocal
Table 1. Deﬁnitions of the tuple ðV; C; S; A; L; p; qÞ underlying active
inference.
a sample space V or non-empty set from which random ﬂuctuations
or outcomes v [ V are drawn
external states C : C  A  V ! R states of the world that
cause sensory states and depend on action
sensory states S : C  A  V ! R the agent’s sensations that
constitute a probabilistic mapping from action and external states
action states A : S  L  V ! R an agent’s action that depends
on its sensory and internal states
internal states L : L  S  V ! R the states of the agent that
cause action and depend on sensory states
ergodic density pðc; s; a; ljmÞ a probability density function over
external c [ C, sensory s [ S, active a [ A and internal states
l [ L for a system denoted by m
variational density q(cjl) an arbitrary probability density function
over external states that is parametrized by internal states
rsif.royalsocietypublishing.org
J R Soc Interface 10: 20130475
2
