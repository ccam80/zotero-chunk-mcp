Matrix formulation of equations used for inference.
Model update
component
Update equation
Explanation
Model-specific description for
explore–exploit task (described
in detail Section 3)
Updating beliefs about
initial states expected
under each allowable
policy.
επ,τ=1 ←1
2
(
ln D + ln(B†
π,τ sπ,τ+1))
+ ln AToτ −ln sπ,τ=1
sπ,τ=1 = σ
( 1
2
(
ln D + ln(B†
π,τ sπ,τ+1))
+ ln AToτ
)
First equation: The variable επ,τ=1 is the state prediction
error with respect to the first time point in a trial.
Minimizing this error corresponds to minimizing VFE
(via gradient descent) and is used to update posterior
beliefs over states. The term (
ln D + ln(B†
π,τ sπ,τ+1))
corresponds to prior beliefs in Bayesian inference, based
on beliefs about the probability of initial states, D, and
the probability of transitions to future states under a
policy, ln(B†
π,τ sπ,τ+1). The term AToτ corresponds to the
likelihood term in Bayesian inference, evaluating how
consistent observed outcomes are with each possible
state. The term ln sπ,τ=1 corresponds to posterior beliefs
over states (for the first time point in a trial) at the
current update iteration.
Second Equation: We move to the solution for the
posterior sπ,τ=1 by setting επ,τ=1 = 0, solving for
ln sπ,τ=1, and then taking the softmax (normalized
exponential) function (denoted σ) to ensure that the
posterior over states is a proper probability distribution
with non-negative values that sums to 1. This equation
is described in more detail in the main text. A
numerical example of the softmax function is also
shown in Appendix A.
Updating beliefs about:
1. Whether the left vs. right
slot machine is more
likely to pay out
on a given trial.
2. The initial choice state
(here, always the
‘start’ state).
Updating beliefs about
all states after the first
time point in a trial that
are expected under each
allowable policy.
επ,τ>1 ←1
2
(
ln (
Bπ,τ−1sπ,τ−1
)
+ ln (
B†
π,τ sπ,τ+1
))
+ ln AToτ −ln sπ,τ>1
sπ,τ>1 = σ
( 1
2
(
ln(Bπ,τ−1sπ,τ−1)
+ ln(B†
π,τ sπ,τ+1))
+ ln AToτ
)
First equation: The variable επ,τ>1 is the state prediction
error with respect to all time points in a trial after the
first time point. Minimizing this error corresponds to
minimizing VFE (via gradient descent) and is used to
update posterior beliefs over states. The term
(
ln(Bπ,τ−1sπ,τ−1) + ln(B†
π,τ sπ,τ+1))
corresponds to prior
beliefs in Bayesian inference, based on beliefs about the
probability of transitions from past states,
ln(Bπ,τ−1sπ,τ−1), and the probability of transitions to
future states, ln(B†
π,τ sπ,τ+1), under a policy. The term
ln AToτ corresponds to the likelihood term in Bayesian
inference, evaluating how consistent observed outcomes
are with each possible state.
Second Equation: As in the previous row, we move to
the solution for the posterior, sπ,τ>1, by setting
επ,τ>1 = 0, solving for ln sπ,τ>1, and then taking the
softmax function (σ). This equation is described in more
detail in the main text.
Updating beliefs about:
1. Whether the left vs.
right slot machine is
more likely to pay
out on a given trial.
2. Beliefs about choice
states after the
initial time point
(here, this depends
on the choice to
take the hint or
to select one of
the slot machines).
