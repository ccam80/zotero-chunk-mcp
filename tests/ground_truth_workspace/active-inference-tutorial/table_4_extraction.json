{
  "paper": "active-inference-tutorial",
  "item_key": "SCPXVBLY",
  "page_num": 19,
  "table_index": 4,
  "caption": "Table 2 (continued).",
  "caption_position": "",
  "headers": [
    "Model",
    "update",
    "Update",
    "equation",
    "Explanation",
    "Model-specific",
    "description",
    "for",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    ""
  ],
  "rows": [
    [
      "component",
      "explore–exploit",
      "task",
      "(described",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "in",
      "detail",
      "Section",
      "3)",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "Expected",
      "free",
      "energy",
      "of",
      "Gπ",
      "=",
      "DKL",
      "[q(o|π)",
      "∥p",
      "(o|C)]",
      "The",
      "first",
      "equation",
      "reproduces",
      "the",
      "‘risk",
      "+",
      "ambiguity’",
      "The",
      "‘risk’",
      "term",
      "–",
      "",
      "",
      ""
    ],
    [
      "each",
      "allowable",
      "policy",
      "expression",
      "for",
      "the",
      "expected",
      "free",
      "energy",
      "of",
      "each",
      "policy",
      "DKL",
      "[q(o|π)",
      "∥p",
      "(o|C)]",
      "=",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "+",
      "Eq(s|π)",
      "[H",
      "[p(o|s)]]",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "(Gπ",
      ")",
      "that",
      "is",
      "explained",
      "in",
      "the",
      "main",
      "text.",
      "The",
      "second",
      "Asπ,τ",
      "·",
      "( ln",
      "Asπ,τ",
      "-ln",
      "Cτ",
      ")",
      "–",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "Gπ",
      "=",
      "∑",
      "( Asπ,τ",
      "·",
      "( ln",
      "Asπ,τ",
      "-ln",
      "Cτ",
      ")",
      "equation",
      "shows",
      "this",
      "same",
      "expression",
      "in",
      "terms",
      "of",
      "the",
      "drives",
      "the",
      "agent",
      "to",
      "select",
      "the"
    ],
    [
      "τ",
      "elements",
      "in",
      "the",
      "POMDP",
      "model",
      "used",
      "in",
      "this",
      "tutorial",
      "(i.e.,",
      "slot",
      "machine",
      "expected",
      "to",
      "be",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "in",
      "matrix",
      "notation).",
      "most",
      "likely",
      "to",
      "pay",
      "out.",
      "If",
      "the",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "-diag",
      "( AT",
      "ln",
      "A)",
      "·",
      "sπ,τ",
      ")",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "Expected",
      "free",
      "energy",
      "evaluates",
      "the",
      "value",
      "of",
      "each",
      "policy",
      "value",
      "of",
      "winning",
      "money",
      "in",
      "Cτ",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "based",
      "on",
      "their",
      "expected",
      "ability",
      "to:",
      "(1)",
      "generate",
      "the",
      "is",
      "high",
      "enough",
      "(i.e.,",
      "if",
      "p",
      "(o|C)",
      "is",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "most",
      "desired",
      "outcomes,",
      "and",
      "(2)",
      "minimize",
      "uncertainty",
      "sufficiently",
      "precise),",
      "this",
      "will",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "about",
      "hidden",
      "states.",
      "Achieving",
      "the",
      "most",
      "desired",
      "deter",
      "the",
      "agent",
      "from",
      "choosing",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "outcomes",
      "corresponds",
      "to",
      "minimizing",
      "the",
      "KL",
      "divergence",
      "to",
      "ask",
      "for",
      "the",
      "hint.",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "between",
      "preferred",
      "observations,",
      "p",
      "(o|C)",
      "=",
      "Cτ",
      ",",
      "and",
      "the",
      "The",
      "‘ambiguity’",
      "term",
      "–",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "observations",
      "expected",
      "under",
      "each",
      "policy,",
      "Eq(s|π)",
      "[H",
      "[p(o|s)]]",
      "=",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "q",
      "(o|π)",
      "=",
      "Asπ,τ",
      "=",
      "oπ,t.",
      "Minimizing",
      "uncertainty",
      "-diag",
      "( AT",
      "ln",
      "A)",
      "·",
      "sπ,τ",
      "–",
      "drives",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "corresponds",
      "to",
      "minimizing",
      "the",
      "expected",
      "entropy",
      "of",
      "the",
      "the",
      "agent",
      "to",
      "minimize",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "likelihood",
      "(Eq(s|π)",
      "[H",
      "[p(o|s)]]",
      "=",
      "-diag",
      "( AT",
      "ln",
      "A)",
      "·",
      "sπ,τ",
      ").",
      "uncertainty",
      "by",
      "asking",
      "for",
      "the",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "Note",
      "that",
      "the",
      "diag()",
      "function",
      "simply",
      "takes",
      "the",
      "diagonal",
      "hint.",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "elements",
      "of",
      "a",
      "matrix",
      "and",
      "places",
      "them",
      "in",
      "a",
      "row",
      "vector.",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "This",
      "is",
      "simply",
      "a",
      "convenient",
      "method",
      "for",
      "extracting",
      "and",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "operating",
      "on",
      "the",
      "correct",
      "matrix",
      "entries",
      "to",
      "calculate",
      "the",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "entropy,",
      "H",
      "[p",
      "(o|s)]",
      "=",
      "-∑",
      "p(o|s)",
      "ln",
      "p",
      "(o|s),",
      "of",
      "the",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "distributions",
      "encoded",
      "within",
      "each",
      "column",
      "in",
      "A.",
      "For",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "simple",
      "numerical",
      "examples",
      "of",
      "calculating",
      "the",
      "risk",
      "and",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "ambiguity",
      "terms,",
      "see",
      "discussion",
      "of",
      "‘outcome",
      "prediction",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "errors’",
      "in",
      "Section",
      "2.4.",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "Marginal",
      "free",
      "energy",
      "of",
      "Fπ",
      "=",
      "Eq(s|π)",
      "[ln",
      "q",
      "(s|π)",
      "The",
      "first",
      "equation",
      "shows",
      "the",
      "marginal",
      "(as",
      "opposed",
      "to",
      "This",
      "would",
      "encode",
      "the",
      "amount",
      ""
    ],
    [
      "each",
      "allowable",
      "policy",
      "variational)",
      "free",
      "energy,",
      "which",
      "is",
      "now",
      "used",
      "in",
      "the",
      "most",
      "of",
      "surprise",
      "(given",
      "a",
      "choice",
      "of",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "-1",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "Eq(sτ-1|π)[ln",
      "p",
      "(sτ",
      "|sτ-1,",
      "π)]",
      "recent",
      "implementations",
      "of",
      "active",
      "inference.",
      "The",
      "second",
      "policy)",
      "when",
      "observing",
      "a",
      "hint",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "2",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "equation",
      "shows",
      "this",
      "same",
      "expression",
      "in",
      "terms",
      "of",
      "the",
      "or",
      "a",
      "win/loss",
      "after",
      "selecting",
      "a",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "-1",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "Eq(sτ+1|π)[ln",
      "p",
      "(sτ",
      "|sτ+1,",
      "π)]",
      "elements",
      "in",
      "the",
      "POMDP",
      "model",
      "used",
      "in",
      "this",
      "tutorial",
      "(i.e.,",
      "specific",
      "slot",
      "machine.",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "2",
      "in",
      "matrix",
      "notation).",
      "Marginal",
      "free",
      "energy",
      "has",
      "a",
      "sightly",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "-ln",
      "p",
      "(oτ",
      "|sτ",
      ")]",
      "different",
      "form",
      "than",
      "the",
      "expressions",
      "for",
      "VFE",
      "that",
      "are",
      "also",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "shown",
      "in",
      "the",
      "text",
      "(and",
      "which",
      "have",
      "been",
      "used",
      "in",
      "many",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "Fπ",
      "=",
      "∑",
      "sπ,τ",
      "·",
      "( ln",
      "sπ,τ",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "previous",
      "papers",
      "in",
      "the",
      "active",
      "inference",
      "literature).",
      "This",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "τ",
      "updated",
      "form",
      "improves",
      "on",
      "certain",
      "limitations",
      "of",
      "the",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "-1",
      "message",
      "passing",
      "algorithms",
      "derived",
      "from",
      "minimization",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "( ln(Bπ,τ-1sπ,τ-1)",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "2",
      "of",
      "VFE",
      "(see",
      "Section",
      "2.3;",
      "also",
      "see",
      "(Parr,",
      "Markovic,",
      "Kiebel,",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "+",
      "ln(B†",
      "sπ,τ+1))",
      "-ln",
      "AToτ",
      ")",
      "&",
      "Friston,",
      "2019).",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "π,τ",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "Marginal",
      "free",
      "energy",
      "evaluates",
      "the",
      "evidence",
      "that",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "inferred",
      "states",
      "provide",
      "for",
      "each",
      "policy",
      "(based",
      "on",
      "new",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "observations",
      "at",
      "each",
      "time",
      "point).",
      "See",
      "the",
      "first",
      "two",
      "rows",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "in",
      "this",
      "table",
      "on",
      "updating",
      "beliefs",
      "about",
      "states",
      "for",
      "an",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "explanation",
      "of",
      "how",
      "each",
      "term",
      "in",
      "the",
      "equation",
      "relates",
      "to",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ],
    [
      "Bayesian",
      "inference.",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      "",
      ""
    ]
  ],
  "num_rows": 54,
  "num_cols": 25,
  "fill_rate": 0.42518518518518517,
  "bbox": [
    37.615997314453125,
    61.89110565185547,
    553.1267700195312,
    473.3529968261719
  ],
  "artifact_type": null,
  "extraction_strategy": "rawdict",
  "footnotes": "",
  "reference_context": "ode a strong prior preference for a large reward, a moderate preference for a small reward, and low preference for no reward. \n\nPrior beliefs about policies _p (π)_ are encoded in a (column) vector _E_ (one row per policy) — increasing the probability that some policies will be chosen over others (i.e., independent of observed/expected outcomes). This can be used to model the influence of habits. For example, if an agent has chosen a particular policy many times in the past, this can lead to a stronger expectation that this policy will be chosen again. In the explore– exploit task example, _E_ could be used to model a simple choice bias in which a participant is more likely to choose one slot machine over another (independent of previous reward learning). However, it is important to distinguish between this type of prior belief and the initial distribution over policies from which actions are sampled before making an observation ( _π_ 0). As explained further below (and in Table 2), this latter distribution depends on _E_ , _G_ , and _γ_ , where the influences of habits and expected future outcomes each have an influence on initial choices. \n\nEach allowable action ( _u_ ) is encoded as a possible state transition (one of several **B** matrices that can be chosen for a state factor). In this case, each possible action is encoded in a vector _U_ , and the possible sequences of actions (where each allowable sequence defines a policy) are encoded in a matrix denoted by **V** (one row per time point, one column per policy, and a third dimension for state factor).",
  "markdown": "**Table 2 (continued).**\n\n| Model | update | Update | equation | Explanation | Model-specific | description | for |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| component | explore–exploit | task | (described |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| in | detail | Section | 3) |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| Expected | free | energy | of | Gπ | = | DKL | [q(o|π) | ∥p | (o|C)] | The | first | equation | reproduces | the | ‘risk | + | ambiguity’ | The | ‘risk’ | term | – |  |  |  |\n| each | allowable | policy | expression | for | the | expected | free | energy | of | each | policy | DKL | [q(o|π) | ∥p | (o|C)] | = |  |  |  |  |  |  |  |  |\n| + | Eq(s|π) | [H | [p(o|s)]] |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| (Gπ | ) | that | is | explained | in | the | main | text. | The | second | Asπ,τ | · | ( ln | Asπ,τ | -ln | Cτ | ) | – |  |  |  |  |  |  |\n| Gπ | = | ∑ | ( Asπ,τ | · | ( ln | Asπ,τ | -ln | Cτ | ) | equation | shows | this | same | expression | in | terms | of | the | drives | the | agent | to | select | the |\n| τ | elements | in | the | POMDP | model | used | in | this | tutorial | (i.e., | slot | machine | expected | to | be |  |  |  |  |  |  |  |  |  |\n| in | matrix | notation). | most | likely | to | pay | out. | If | the |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| -diag | ( AT | ln | A) | · | sπ,τ | ) |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| Expected | free | energy | evaluates | the | value | of | each | policy | value | of | winning | money | in | Cτ |  |  |  |  |  |  |  |  |  |  |\n| based | on | their | expected | ability | to: | (1) | generate | the | is | high | enough | (i.e., | if | p | (o|C) | is |  |  |  |  |  |  |  |  |\n| most | desired | outcomes, | and | (2) | minimize | uncertainty | sufficiently | precise), | this | will |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| about | hidden | states. | Achieving | the | most | desired | deter | the | agent | from | choosing |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| outcomes | corresponds | to | minimizing | the | KL | divergence | to | ask | for | the | hint. |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| between | preferred | observations, | p | (o|C) | = | Cτ | , | and | the | The | ‘ambiguity’ | term | – |  |  |  |  |  |  |  |  |  |  |  |\n| observations | expected | under | each | policy, | Eq(s|π) | [H | [p(o|s)]] | = |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| q | (o|π) | = | Asπ,τ | = | oπ,t. | Minimizing | uncertainty | -diag | ( AT | ln | A) | · | sπ,τ | – | drives |  |  |  |  |  |  |  |  |  |\n| corresponds | to | minimizing | the | expected | entropy | of | the | the | agent | to | minimize |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| likelihood | (Eq(s|π) | [H | [p(o|s)]] | = | -diag | ( AT | ln | A) | · | sπ,τ | ). | uncertainty | by | asking | for | the |  |  |  |  |  |  |  |  |\n| Note | that | the | diag() | function | simply | takes | the | diagonal | hint. |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| elements | of | a | matrix | and | places | them | in | a | row | vector. |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| This | is | simply | a | convenient | method | for | extracting | and |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| operating | on | the | correct | matrix | entries | to | calculate | the |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| entropy, | H | [p | (o|s)] | = | -∑ | p(o|s) | ln | p | (o|s), | of | the |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| distributions | encoded | within | each | column | in | A. | For |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| simple | numerical | examples | of | calculating | the | risk | and |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| ambiguity | terms, | see | discussion | of | ‘outcome | prediction |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| errors’ | in | Section | 2.4. |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| Marginal | free | energy | of | Fπ | = | Eq(s|π) | [ln | q | (s|π) | The | first | equation | shows | the | marginal | (as | opposed | to | This | would | encode | the | amount |  |\n| each | allowable | policy | variational) | free | energy, | which | is | now | used | in | the | most | of | surprise | (given | a | choice | of |  |  |  |  |  |  |\n| -1 |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| Eq(sτ-1|π)[ln | p | (sτ | |sτ-1, | π)] | recent | implementations | of | active | inference. | The | second | policy) | when | observing | a | hint |  |  |  |  |  |  |  |  |\n| 2 |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| equation | shows | this | same | expression | in | terms | of | the | or | a | win/loss | after | selecting | a |  |  |  |  |  |  |  |  |  |  |\n| -1 |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| Eq(sτ+1|π)[ln | p | (sτ | |sτ+1, | π)] | elements | in | the | POMDP | model | used | in | this | tutorial | (i.e., | specific | slot | machine. |  |  |  |  |  |  |  |\n| 2 | in | matrix | notation). | Marginal | free | energy | has | a | sightly |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| -ln | p | (oτ | |sτ | )] | different | form | than | the | expressions | for | VFE | that | are | also |  |  |  |  |  |  |  |  |  |  |\n| shown | in | the | text | (and | which | have | been | used | in | many |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| Fπ | = | ∑ | sπ,τ | · | ( ln | sπ,τ |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| previous | papers | in | the | active | inference | literature). | This |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| τ | updated | form | improves | on | certain | limitations | of | the |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| -1 | message | passing | algorithms | derived | from | minimization |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| ( ln(Bπ,τ-1sπ,τ-1) |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| 2 | of | VFE | (see | Section | 2.3; | also | see | (Parr, | Markovic, | Kiebel, |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| + | ln(B† | sπ,τ+1)) | -ln | AToτ | ) | & | Friston, | 2019). |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| π,τ |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| Marginal | free | energy | evaluates | the | evidence | that |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| inferred | states | provide | for | each | policy | (based | on | new |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| observations | at | each | time | point). | See | the | first | two | rows |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| in | this | table | on | updating | beliefs | about | states | for | an |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| explanation | of | how | each | term | in | the | equation | relates | to |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| Bayesian | inference. |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |"
}