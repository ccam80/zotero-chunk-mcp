{
  "table_id": "SCPXVBLY_table_2_p20",
  "paper": "active-inference-tutorial",
  "item_key": "SCPXVBLY",
  "page_num": 20,
  "table_index": 5,
  "caption": "Table 2 (continued).",
  "headers": [
    "Model update component",
    "Update equation",
    "Explanation",
    "Model-specific description for explore–exploit task (described in detail Section 3)"
  ],
  "rows": [
    [
      "Expected free energy precision",
      "p(γ) = Γ(1, β)\nE[γ] = γ = 1/β\nIterated to convergence:\nπ0 ← σ(ln E − γG)\nπ ← σ(ln E − F − γG)\nGerror ← (π − π0) · (−G)\nβupdate ← β − β0 + Gerror\nβ ← β − βupdate/ψ\nγ ← 1/β",
      "The β term, and its prior value β0, is a hyperparameter on the expected free energy precision term (γ). Specifically, β is the ‘rate’ parameter of a gamma distribution (Γ) with a ‘shape’ parameter value of 1. The expected value of this distribution, E[γ] = γ, is equal to the reciprocal of β. Note that we use the non-italicized γ to refer to the random variable and use the italicized γ to refer to the scalar value of that variable. This scalar is what is subsequently updated based on the equations shown here.\nThe γ term controls the precision of G, based on the agent’s confidence in its estimates of expected free energy. This confidence changes when new observations are consistent or inconsistent with G. More specifically, γ modulates the influence of G on policy selection based upon a G prediction error (Gerror). This is calculated based on the difference between the initial distribution over policies (π0) and the posterior distribution after making a new observation (π). The difference between these terms reflects the extent to which new observations (scored by F) make policies more or less likely. If the vector encoding the posterior over policies increases in magnitude in comparison to the prior, and still points in the same direction, the difference vector between the posterior and the prior will point in the same direction as the −G vector (i.e., less than a 90° angle apart; see Fig. 9). If so, the value of γ will increase, thereby increasing the impact of G on policy selection. In contrast, if the difference vector between the posterior and the prior does not point in the same direction as the −G vector (i.e., greater than a 90° angle apart), γ will decrease and thereby reduce the impact of G on policy selection (i.e., as the agent’s confidence in its estimates of expected free energy has decreased).\nNote that the βupdate term mediating these updates technically corresponds to the gradient of free energy with respect to γ (∇γF). The subsequent update in the value of γ is such that G contributes to the posterior over policies in an optimal manner. β and Gerror are often discussed in relation to dopamine in the active inference literature.\nNote that β0 is the initial prior (which is not updated), and β is the initial posterior, which is subsequently updated to provide a new estimate for γ = 1/β. The variable ψ is a step size parameter that reduces the magnitude of each update and promotes stable convergence to final values of γ. For a derivation of these equations, see Appendix in Sales, Friston, Jones, Pickering, and Moran (2019).",
      "A higher value for β would reduce an agent’s confidence in the best policy based on the values in G. This might lead the agent to select a slot machine more randomly or based to a greater extent on its past choices (i.e., if it has a precise prior over policies in the vector E)."
    ]
  ],
  "notes": "This is the final row of Table 2. Variable names from rawtext: π0 (pi-zero), Gerror, βupdate, β0 (beta-zero), ψ (psi). The gamma distribution symbol is Γ.",
  "verified": true,
  "footnotes": "Table note: The term B†π,τ denotes the transpose of Bπ,τ with normalized columns (i.e., columns that sum to 1). Note that you may commonly see the dot (·) notation used in the active inference literature to denote transposed matrix multiplication, such as A · oτ, which means Aᵀoτ (we use the latter notation here). When A matrices have more than two dimensions (i.e., when they are tensors), the transpose is applied to the two-dimensional matrix associated with each value of the other dimensions. The σ symbol indicates a softmax operation (for an introduction see Appendix A), which transforms vector values to make up a proper probability distribution (i.e., with non-negative values that sum to 1). Italicized variables indicate vectors (or single numbers [scalars] in the case of β and γ). Bold, non-italicized variables indicate matrices. Subscripts indicate conditional probabilities; e.g., sπ,τ = p(sτ|π)."
}
