{
  "table_id": "SCPXVBLY_table_2",
  "paper": "active-inference-tutorial",
  "item_key": "SCPXVBLY",
  "page_num": 20,
  "table_index": 5,
  "caption": "Table 2 (continued).",
  "headers": ["Model update component", "Update equation", "Explanation", "Model-specific description for explore-exploit task (described in detail Section 3)"],
  "rows": [
    ["Expected free energy precision", "p(\u03b3) = \u0393(1, \u03b2)\nE[\u03b3] = 1/\u03b2\nIterated to convergence:\n\u03c0\u1d47 \u2190 \u03c3(ln E \u2212 \u03b3G)\nG\u03c4\u02b3\u02b3 \u2190 (\u03c0\u1d47 \u2212 \u03c0\u2080) \u00b7 (\u2212G)\n\u03b2\u1d4a\u1d43\u02b3\u02b3 \u2190 \u03b2 + \u03b2\u1d4a\u1d43\u02b3\u02b3\n\u03b3 \u2190 1/\u03b2", "The \u03b2 term, and its prior value \u03b2\u2080, is a hyperparameter on the expected free energy precision term (\u03b3). Specifically, \u03b2 is the \u2018rate\u2019 parameter of a gamma distribution (T) with a \u2018shape\u2019 parameter value of 1. The expected value of this distribution, E[\u03b3] = \u03b3, is equal to the reciprocal of \u03b2. Note that we use the non-italicized \u03b3 to refer to the matrix and that we use the italicized \u03b3 to refer to the scalar value of that variable. This scalar is what is subsequently updated based on the equations shown here.\nThe \u03b3 term controls the precision of G, based on the agent\u2019s confidence in its estimates of expected free energy. This confidence changes when new observations are consistent or inconsistent with G. More specifically, \u03b3 modulates the influence of G on policy selection based on a G prediction error (\u03b5\u03b3\u02b3\u02b3). This is calculated based on the difference between the initial distribution over policies (\u03c0\u2080) and the posterior distribution after making a new observation (\u03c0\u1d47). The difference between these terms reflects the extent to which new observations (scored by F) make policies more or less likely. If the vector encoding the posterior over policies increases in magnitude in comparison to the prior, and still points in the same direction, the angle between the posterior and the prior will point in the same direction as the \u2212G vector (i.e., less than a 90\u00b0 angle apart; see Fig. 9). If so, the value of \u03b3 will increase, thereby increasing the impact of G on policy selection. In contrast, if the difference vector between the posterior and the prior does not point in the same direction as the \u2212G vector (i.e., greater than a 90\u00b0 angle apart), \u03b3 will decrease and thereby reduce the impact of G on policy selection (i.e., as the agent\u2019s confidence in its estimates of expected free energy has decreased).\nNote that the \u03b2\u1d4a\u1d43\u02b3\u02b3 term mediating these updates technically corresponds to the gradient of free energy with respect to \u03b3 (\u2207\u03b3F). The subsequent update in the value of \u03b3 is such that G contributes to the posterior probability of policies in an optimal manner. \u03b2 and \u03b3 are often discussed in relation to dopamine in the active inference literature.\nNote that \u03b2\u2080 is the initial prior (which is not updated), and \u03b2 is the initial posterior, which is subsequently updated to provide a new estimate for \u03b3 = 1/\u03b2. The variable \u03c6 is a step size parameter that reduces the magnitude of each update and promotes stable convergence to final values of \u03b3. For a derivation of these equations, see Appendix in Sales, Friston, Jones, Pickering, and Moran (2019).", "A higher value for \u03b2 would reduce an agent\u2019s confidence in the best policy based on the values in G. This might lead the agent to select a slot machine more randomly or based to a greater extent on its past choices (i.e., if it has a precise prior over policies in the vector E)."]
  ],
  "notes": "This is the final row of Table 2. Table note at bottom of page: 'The term B\u1d40\u03c4 denotes the transpose of B\u03c4, with normalized columns (i.e., columns that sum to 1). Note that you may commonly see the dot (.) notation used in the active inference literature to denote transposed matrix multiplication, such as B\u1d40... which means A\u1d40... (see the latex section here...' (truncated at page bottom).",
  "verified": false
}